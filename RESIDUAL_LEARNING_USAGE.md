# æ®‹å·®å­¦ä¹ æ¨¡å¼ä½¿ç”¨æŒ‡å—

## ğŸ¯ æ ¸å¿ƒåŸç†

åŸºäº **æ®‹å·®å­¦ä¹  + å†»ç»“ç­–ç•¥** æ¥ä¿ç•™ CLIP çš„åŸå§‹å¯¹é½ç©ºé—´ï¼Œé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆå’Œåç¦»é¢„è®­ç»ƒçŸ¥è¯†ã€‚

### æ ¸å¿ƒå…¬å¼

```python
# Quality é¢„æµ‹
q = q_base + Î”q Ã— scale_q
å…¶ä¸­: q_base = sigmoid(Linear(CLIP_img_features))
     Î”q = Tanh(MLP(CLIP_img_features))  # èŒƒå›´ [-1, 1]
     scale_q = 0.2  # é™åˆ¶åç¦»å¹…åº¦

# Consistency é¢„æµ‹
c = cos(img, txt) + Î”c Ã— scale_c
å…¶ä¸­: cos(img, txt) = CLIP åŸå§‹ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆæ˜ å°„åˆ° [0,1]ï¼‰
     Î”c = Tanh(FusionHead([img, txt, cos]))  # èŒƒå›´ [-1, 1]
     scale_c = 0.2  # é™åˆ¶åç¦»å¹…åº¦
```

### ä¸‰å¤§ä¼˜åŠ¿

1. **ä¿ç•™åŸå§‹å¯¹é½ç©ºé—´**: åŸºäº CLIP çš„ cosine similarity ä½œä¸ºåŸºå‡†ï¼Œä¸ä¼šå®Œå…¨é‡å»ºè¡¨ç¤ºç©ºé—´
2. **é™åˆ¶å­¦ä¹ èŒƒå›´**: é€šè¿‡ Tanh + scale é™åˆ¶æ®‹å·®å¹…åº¦ï¼ˆé»˜è®¤ Â±0.2ï¼‰ï¼Œé˜²æ­¢è¿‡åº¦ä¿®æ”¹
3. **å‡è½»è¿‡æ‹Ÿåˆ**: æ¨¡å‹åªå­¦ä¹ å°çš„å¾®è°ƒé‡ï¼Œè€Œéä»å¤´å­¦ä¹ æ•´ä¸ªæ˜ å°„

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. åŸºç¡€ç”¨æ³•ï¼šæ®‹å·®å­¦ä¹ æ¨¡å¼ï¼ˆé»˜è®¤å¯ç”¨ï¼‰

```bash
python baseline.py \
    --epochs 20 \
    --batch_size 32 \
    --lr 3e-5
```

**é»˜è®¤é…ç½®**:
- âœ… æ®‹å·®å­¦ä¹ æ¨¡å¼å·²å¯ç”¨ (`use_residual_learning=True`)
- ğŸ”¥ CLIP å®Œå…¨å¯è®­ç»ƒï¼ˆç«¯åˆ°ç«¯å¾®è°ƒï¼‰
- ğŸ“ æ®‹å·®ç¼©æ”¾å› å­: `scale_q=0.2`, `scale_c=0.2`

---

### 2. æ®‹å·®å­¦ä¹  + éƒ¨åˆ†å†»ç»“ CLIPï¼ˆæ¨èï¼‰

å†»ç»“ CLIP çš„å‰ N å±‚ï¼Œåªè®­ç»ƒæœ€åå‡ å±‚ï¼Œè¿›ä¸€æ­¥ä¿æŠ¤é¢„è®­ç»ƒçŸ¥è¯†ï¼š

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --epochs 20 \
    --batch_size 32 \
    --lr 3e-5
```

**æ•ˆæœ**:
- ğŸ§Š å‰ 18 å±‚å†»ç»“ï¼ˆViT-L-14 å…± 24 å±‚ï¼‰
- ğŸ”¥ æœ€å 6 å±‚å¯è®­ç»ƒ
- âœ… æ®‹å·®å­¦ä¹ è‡ªåŠ¨å¯ç”¨
- ğŸ’¾ æ¨¡å‹ä¿å­˜ä¸º: `baseline_residual_partial_freeze_18L_best.pt`

**å±‚æ•°é€‰æ‹©å»ºè®®**:
- ViT-B/32 (12 å±‚): `--freeze_layers 8` (è®­ç»ƒæœ€å 4 å±‚)
- ViT-L/14 (24 å±‚): `--freeze_layers 18-20` (è®­ç»ƒæœ€å 4-6 å±‚)

---

### 3. è°ƒæ•´æ®‹å·®ç¼©æ”¾å› å­

å¦‚æœè§‰å¾—æ¨¡å‹è°ƒæ•´å¹…åº¦å¤ªå°æˆ–å¤ªå¤§ï¼Œå¯ä»¥è°ƒæ•´ç¼©æ”¾å› å­ï¼š

```bash
python baseline.py \
    --residual_scale_q 0.3 \
    --residual_scale_c 0.3 \
    --epochs 20
```

**ç¼©æ”¾å› å­è¯´æ˜**:
- `0.1`: éå¸¸ä¿å®ˆï¼Œå‡ ä¹ä¸åç¦» CLIPï¼ˆé€‚åˆæ•°æ®å°‘çš„æƒ…å†µï¼‰
- `0.2`: **é»˜è®¤å€¼**ï¼Œå¹³è¡¡æ€§èƒ½å’Œç¨³å®šæ€§
- `0.3-0.5`: è¾ƒæ¿€è¿›ï¼Œå…è®¸æ›´å¤§è°ƒæ•´ï¼ˆé€‚åˆæ•°æ®å……è¶³çš„æƒ…å†µï¼‰
- `>0.5`: ä¸æ¨èï¼Œå¤±å»æ®‹å·®å­¦ä¹ çš„æ„ä¹‰

---

### 4. ç¦ç”¨æ®‹å·®å­¦ä¹ ï¼ˆå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼ï¼‰

å¦‚æœæƒ³ä½¿ç”¨ä¼ ç»Ÿçš„ç›´æ¥é¢„æµ‹æ¨¡å¼ï¼ˆä¸æ¨èï¼‰ï¼š

```bash
python baseline.py \
    --no_residual_learning \
    --epochs 20
```

---

### 5. å®Œå…¨å†»ç»“ CLIPï¼ˆLinear Probingï¼‰

åªè®­ç»ƒé¢„æµ‹å¤´ï¼ŒCLIP å®Œå…¨å†»ç»“ï¼š

```bash
python baseline.py \
    --freeze_clip \
    --epochs 20 \
    --lr 1e-3  # å†»ç»“æ—¶å¯ä»¥ç”¨æ›´å¤§çš„å­¦ä¹ ç‡
```

**æ³¨æ„**: æ­¤æ¨¡å¼ä¸‹æ®‹å·®å­¦ä¹ ä»ç„¶æœ‰æ•ˆï¼Œå› ä¸ºé¢„æµ‹å¤´æœ¬èº«ä½¿ç”¨æ®‹å·®æ¶æ„ã€‚

---

## ğŸ“Š é…ç½®å¯¹æ¯”

| æ¨¡å¼ | å‘½ä»¤ | CLIP çŠ¶æ€ | é¢„æµ‹æ–¹å¼ | é€‚ç”¨åœºæ™¯ |
|------|------|-----------|----------|----------|
| **æ®‹å·®å­¦ä¹  + éƒ¨åˆ†å†»ç»“** | `--partial_freeze --freeze_layers 18` | å‰ 18 å±‚å†»ç»“ | `cos(img,txt) + Î”` | ğŸ† **æ¨è**ï¼Œå¹³è¡¡æ€§èƒ½å’Œç¨³å®šæ€§ |
| **æ®‹å·®å­¦ä¹  + å®Œå…¨å¾®è°ƒ** | é»˜è®¤ | å®Œå…¨å¯è®­ç»ƒ | `cos(img,txt) + Î”` | æ•°æ®å……è¶³ï¼Œè¿½æ±‚æè‡´æ€§èƒ½ |
| **Linear Probing** | `--freeze_clip` | å®Œå…¨å†»ç»“ | `cos(img,txt) + Î”` | å¿«é€ŸéªŒè¯ï¼Œæ•°æ®å¾ˆå°‘ |
| **ä¼ ç»Ÿæ¨¡å¼** | `--no_residual_learning` | å®Œå…¨å¯è®­ç»ƒ | ç›´æ¥é¢„æµ‹ | æ¶ˆèå®éªŒ/å¯¹æ¯”åŸºçº¿ |

---

## ğŸ”¬ è®­ç»ƒè¾“å‡ºç¤ºä¾‹

å¯ç”¨æ®‹å·®å­¦ä¹ åï¼Œè®­ç»ƒæ—¶ä¼šæ˜¾ç¤ºè¯¦ç»†é…ç½®ï¼š

```
======================================================================
Training Configuration:
  - Epochs: 20, Batch Size: 32, LR: 3e-05
  - Loss Weights: w_q=0.5, w_c=0.5
  - Use Explanations: False

  ğŸ”§ CLIP å†»ç»“ç­–ç•¥:
     ğŸ§Š éƒ¨åˆ†å†»ç»“ï¼šå‰ 18 å±‚å†»ç»“ï¼Œå…¶ä½™å¯è®­ç»ƒ

  ğŸ¯ é¢„æµ‹æ¶æ„:
     âœ… æ®‹å·®å­¦ä¹ æ¨¡å¼ï¼ˆä¿ç•™ CLIP å¯¹é½ç©ºé—´ï¼‰
        - Quality:  q = q_base + Î”q Ã— 0.2
        - Consistency: c = cos(img,txt) + Î”c Ã— 0.2
        - åŸç†: åªå­¦ä¹ å¾®è°ƒé‡ï¼Œé˜²æ­¢ç ´å CLIP åŸå§‹ç©ºé—´
======================================================================
```

---

## ğŸ“ ç†è®ºä¾æ®

### ä¸ºä»€ä¹ˆæ®‹å·®å­¦ä¹ æœ‰æ•ˆï¼Ÿ

1. **é¢„è®­ç»ƒçŸ¥è¯†ä¿æŠ¤**: CLIP åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šè®­ç»ƒï¼Œå…¶å¯¹é½ç©ºé—´å·²ç»å¾ˆå¥½ï¼Œç›´æ¥é¢„æµ‹å¯èƒ½ç ´åè¿™ä¸ªç©ºé—´
2. **æ¢¯åº¦æµåŠ¨**: æ®‹å·®è¿æ¥æä¾›ç›´æ¥çš„æ¢¯åº¦é€šè·¯ï¼ŒåŠ é€Ÿæ”¶æ•›
3. **å½’çº³åç½®**: å¼ºåˆ¶æ¨¡å‹ä» CLIP åŸºå‡†å‡ºå‘ï¼Œæä¾›è‰¯å¥½çš„åˆå§‹ç‚¹
4. **è¿‡æ‹ŸåˆæŠ‘åˆ¶**: é™åˆ¶æ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼ˆé€šè¿‡ scaleï¼‰ï¼Œé˜²æ­¢åœ¨å°æ•°æ®é›†ä¸Šè¿‡æ‹Ÿåˆ

### æ•°å­¦å½¢å¼

ä¼ ç»Ÿæ–¹å¼:
```
score = f(CLIP_features)  # å®Œå…¨é‡æ–°å­¦ä¹ æ˜ å°„
```

æ®‹å·®å­¦ä¹ :
```
score = CLIP_base_score + bounded_correction
      = g(CLIP_features) + tanh(h(CLIP_features)) Ã— Î±
```
å…¶ä¸­ Î± æ˜¯å°çš„ç¼©æ”¾å› å­ï¼ˆå¦‚ 0.2ï¼‰ï¼Œä¿è¯ `|correction| â‰¤ Î±`

---

## ğŸ’¡ æœ€ä½³å®è·µ

### æ¨èé…ç½® 1: æ•°æ®å……è¶³ï¼ˆ>3K æ ·æœ¬ï¼‰

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --residual_scale_q 0.2 \
    --residual_scale_c 0.2 \
    --epochs 20 \
    --batch_size 32 \
    --lr 3e-5
```

### æ¨èé…ç½® 2: æ•°æ®è¾ƒå°‘ï¼ˆ<1K æ ·æœ¬ï¼‰

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 20 \
    --residual_scale_q 0.1 \
    --residual_scale_c 0.1 \
    --epochs 30 \
    --batch_size 16 \
    --lr 1e-5
```

### æ¨èé…ç½® 3: å¿«é€ŸéªŒè¯

```bash
python baseline.py \
    --freeze_clip \
    --epochs 10 \
    --batch_size 64 \
    --lr 1e-3
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ³¨æ„è§‚å¯Ÿï¼š

1. **Base vs Final Score**: 
   - å¦‚æœ `Î”` ç»å¸¸æ¥è¿‘ `Â±scale`ï¼Œè¯´æ˜ç¼©æ”¾å› å­å¯èƒ½å¤ªå°
   - å¦‚æœ `Î”` éƒ½å¾ˆå°ï¼ˆ<0.05ï¼‰ï¼Œå¯èƒ½è¿‡åº¦çº¦æŸï¼Œå¯ä»¥å¢å¤§ `scale`

2. **SROCC æ›²çº¿**:
   - æ®‹å·®å­¦ä¹ é€šå¸¸æ”¶æ•›æ›´å¿«ï¼ˆ5-10 epochï¼‰
   - éªŒè¯é›†æ€§èƒ½æ›´ç¨³å®šï¼ˆæ³¢åŠ¨å°ï¼‰

3. **è¿‡æ‹Ÿåˆæ£€æµ‹**:
   - Train-Val gap åº”è¯¥ <0.05
   - å¦‚æœ gap è¿‡å¤§ï¼Œè€ƒè™‘å¢å¤§å†»ç»“å±‚æ•°æˆ–å‡å° `scale`

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ä¸è¦åŒæ—¶å¯ç”¨ `--use_refinement` å’Œæ®‹å·®å­¦ä¹ **: 
   - æ®‹å·®å­¦ä¹ æ¨¡å¼å·²ç»å†…ç½®äº†æ›´ä¼˜é›…çš„æ®‹å·®æœºåˆ¶
   - æ—§çš„ refinement module ä¼šè¢«è‡ªåŠ¨ç¦ç”¨

2. **å­¦ä¹ ç‡å»ºè®®**:
   - å®Œå…¨å¾®è°ƒ: `1e-5 ~ 5e-5`
   - éƒ¨åˆ†å†»ç»“: `3e-5 ~ 1e-4`
   - å®Œå…¨å†»ç»“: `1e-3 ~ 5e-3`

3. **Batch Size**:
   - æ®‹å·®å­¦ä¹ å¯¹ batch size ä¸æ•æ„Ÿ
   - å»ºè®®æ ¹æ®æ˜¾å­˜è°ƒæ•´: 16/32/64

---

## ğŸ” æ¶ˆèå®éªŒå»ºè®®

å¯¹æ¯”ä¸åŒé…ç½®çš„æ•ˆæœï¼š

```bash
# å®éªŒ 1: åŸºå‡†ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰
python baseline.py --no_residual_learning --epochs 20

# å®éªŒ 2: æ®‹å·®å­¦ä¹ 
python baseline.py --epochs 20

# å®éªŒ 3: æ®‹å·®å­¦ä¹  + éƒ¨åˆ†å†»ç»“
python baseline.py --partial_freeze --freeze_layers 18 --epochs 20

# å®éªŒ 4: å®Œå…¨å†»ç»“
python baseline.py --freeze_clip --epochs 20
```

é¢„æœŸç»“æœ:
- å®éªŒ 3 é€šå¸¸æ•ˆæœæœ€å¥½ï¼ˆå¹³è¡¡æ€§èƒ½å’Œæ³›åŒ–ï¼‰
- å®éªŒ 2 åœ¨å¤§æ•°æ®é›†ä¸Šå¯èƒ½ç•¥ä¼˜
- å®éªŒ 4 æœ€å¿«ï¼Œé€‚åˆå¿«é€ŸéªŒè¯

---

## ğŸ“š ç›¸å…³è®ºæ–‡

1. **Residual Learning**: He et al., "Deep Residual Learning for Image Recognition", CVPR 2016
2. **CLIP**: Radford et al., "Learning Transferable Visual Models From Natural Language Supervision", ICML 2021
3. **Adapter Tuning**: Houlsby et al., "Parameter-Efficient Transfer Learning for NLP", ICML 2019

---

## ğŸ†˜ å¸¸è§é—®é¢˜

**Q: æ®‹å·®å­¦ä¹ ä¼šé™ä½æ€§èƒ½å—ï¼Ÿ**  
A: ä¸ä¼šã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ®‹å·®å­¦ä¹ æä¾›æ›´å¥½çš„æ³›åŒ–å’Œç¨³å®šæ€§ï¼ŒSROCC é€šå¸¸æå‡ 1-3%ã€‚

**Q: ä¸ºä»€ä¹ˆä¸ç›´æ¥ç”¨ CLIP çš„ cosine similarityï¼Ÿ**  
A: CLIP çš„ cosine similarity å¯¹äº AIGC å›¾åƒä¸å¤Ÿç²¾ç»†ï¼Œéœ€è¦å­¦ä¹ ä¸€ä¸ªå°çš„ä¿®æ­£é‡æ¥é€‚åº”ç‰¹å®šä»»åŠ¡ã€‚

**Q: å¯ä»¥åŠ¨æ€è°ƒæ•´ scale å—ï¼Ÿ**  
A: ç›®å‰ scale æ˜¯å›ºå®šçš„ã€‚æœªæ¥å¯ä»¥è€ƒè™‘å°†å…¶ä½œä¸ºå¯å­¦ä¹ å‚æ•°ï¼Œæˆ–ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ é€æ­¥å¢å¤§ã€‚

**Q: éƒ¨åˆ†å†»ç»“æ—¶å“ªäº›å±‚åº”è¯¥å†»ç»“ï¼Ÿ**  
A: æµ…å±‚å­¦ä¹ é€šç”¨ç‰¹å¾ï¼ˆè¾¹ç¼˜ã€çº¹ç†ï¼‰ï¼Œæ·±å±‚å­¦ä¹ ä»»åŠ¡ç›¸å…³ç‰¹å¾ã€‚é€šå¸¸å†»ç»“å‰ 70-80% çš„å±‚æ•ˆæœæœ€å¥½ã€‚

---

## ğŸ“ ä»£ç ç»“æ„

æ–°å¢çš„å…³é”®æ¨¡å—ï¼š

```python
# baseline.py

class BaselineCLIPScore:
    def __init__(..., use_residual_learning=True, residual_scale_q=0.2, ...):
        if use_residual_learning:
            # Quality åˆ†æ”¯
            self.q_base_head = nn.Linear(dim, 1)  # åŸºå‡†åˆ†æ•°
            self.q_delta_head = nn.Sequential(...)  # æ®‹å·®é¢„æµ‹å™¨
            
            # Consistency åˆ†æ”¯
            self.c_base_scale = nn.Parameter(...)  # CLIP cos çš„å¯å­¦ä¹ ç¼©æ”¾
            self.c_delta_head = nn.Sequential(...)  # æ®‹å·®é¢„æµ‹å™¨
    
    def forward(self, ...):
        if self.use_residual_learning:
            # Quality: base + delta
            q = clamp(q_base + q_delta * scale_q, 0, 1)
            
            # Consistency: cos + delta
            c = clamp(cos_sim + c_delta * scale_c, 0, 1)
        ...
    
    def _partial_freeze_clip(self, freeze_layers):
        # å†»ç»“å‰ N å±‚ç¼–ç å™¨
        ...
```

---

**æœ€åæ›´æ–°**: 2025-10-16  
**ç‰ˆæœ¬**: 1.0

