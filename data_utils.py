#!/usr/bin/env python3
"""
æ•°æ®é¢„å¤„ç†å’Œåˆ†æå·¥å…·
ç”¨äºæ•°æ®é›†ç»Ÿè®¡ã€å¯è§†åŒ–å’Œé¢„å¤„ç†
"""

import argparse
import os
from typing import Optional, Tuple
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from tqdm import tqdm

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®ç»˜å›¾é£æ ¼
sns.set_style("whitegrid")
sns.set_palette("husl")


class DatasetAnalyzer:
    """æ•°æ®é›†åˆ†æå™¨"""
    
    def __init__(self, csv_path: str, image_dir: str, output_dir: str = "data_analysis"):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            csv_path: CSV æ–‡ä»¶è·¯å¾„
            image_dir: å›¾åƒç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        """
        self.df = pd.read_csv(csv_path)
        self.image_dir = image_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        print(f"ğŸ“‚ åŠ è½½æ•°æ®é›†: {csv_path}")
        print(f"ğŸ“Š æ ·æœ¬æ•°: {len(self.df)}")
    
    def print_basic_stats(self):
        """æ‰“å°åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æ•°æ®é›†åŸºæœ¬ç»Ÿè®¡")
        print("=" * 80)
        
        print(f"\næ ·æœ¬æ€»æ•°: {len(self.df)}")
        
        if 'mos_quality' in self.df.columns:
            print(f"\nğŸ¨ Quality åˆ†æ•°:")
            print(f"  â€¢ å‡å€¼: {self.df['mos_quality'].mean():.3f}")
            print(f"  â€¢ æ ‡å‡†å·®: {self.df['mos_quality'].std():.3f}")
            print(f"  â€¢ æœ€å°å€¼: {self.df['mos_quality'].min():.3f}")
            print(f"  â€¢ æœ€å¤§å€¼: {self.df['mos_quality'].max():.3f}")
            print(f"  â€¢ ä¸­ä½æ•°: {self.df['mos_quality'].median():.3f}")
        
        if 'mos_align' in self.df.columns:
            print(f"\nğŸ”— Consistency åˆ†æ•°:")
            print(f"  â€¢ å‡å€¼: {self.df['mos_align'].mean():.3f}")
            print(f"  â€¢ æ ‡å‡†å·®: {self.df['mos_align'].std():.3f}")
            print(f"  â€¢ æœ€å°å€¼: {self.df['mos_align'].min():.3f}")
            print(f"  â€¢ æœ€å¤§å€¼: {self.df['mos_align'].max():.3f}")
            print(f"  â€¢ ä¸­ä½æ•°: {self.df['mos_align'].median():.3f}")
        
        if 'prompt' in self.df.columns:
            prompt_lengths = self.df['prompt'].str.len()
            print(f"\nğŸ“ Prompt ç»Ÿè®¡:")
            print(f"  â€¢ å¹³å‡é•¿åº¦: {prompt_lengths.mean():.1f} å­—ç¬¦")
            print(f"  â€¢ æœ€çŸ­: {prompt_lengths.min()} å­—ç¬¦")
            print(f"  â€¢ æœ€é•¿: {prompt_lengths.max()} å­—ç¬¦")
        
        print("=" * 80 + "\n")
    
    def plot_score_distributions(self, save_path: Optional[str] = None):
        """ç»˜åˆ¶åˆ†æ•°åˆ†å¸ƒå›¾"""
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # Quality ç›´æ–¹å›¾
        if 'mos_quality' in self.df.columns:
            ax = axes[0, 0]
            ax.hist(self.df['mos_quality'], bins=30, color='skyblue',
                   edgecolor='black', alpha=0.7)
            ax.axvline(self.df['mos_quality'].mean(), color='red',
                      linestyle='--', linewidth=2,
                      label=f'å‡å€¼ ({self.df["mos_quality"].mean():.2f})')
            ax.set_xlabel('Quality åˆ†æ•°', fontsize=12)
            ax.set_ylabel('é¢‘æ•°', fontsize=12)
            ax.set_title('Quality åˆ†æ•°åˆ†å¸ƒ', fontsize=13, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # Quality ç®±çº¿å›¾
        if 'mos_quality' in self.df.columns:
            ax = axes[0, 1]
            ax.boxplot([self.df['mos_quality']], vert=True, labels=['Quality'],
                      patch_artist=True, boxprops=dict(facecolor='skyblue'))
            ax.set_ylabel('åˆ†æ•°', fontsize=12)
            ax.set_title('Quality åˆ†æ•°ç®±çº¿å›¾', fontsize=13, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        # Consistency ç›´æ–¹å›¾
        if 'mos_align' in self.df.columns:
            ax = axes[1, 0]
            ax.hist(self.df['mos_align'], bins=30, color='orange',
                   edgecolor='black', alpha=0.7)
            ax.axvline(self.df['mos_align'].mean(), color='red',
                      linestyle='--', linewidth=2,
                      label=f'å‡å€¼ ({self.df["mos_align"].mean():.2f})')
            ax.set_xlabel('Consistency åˆ†æ•°', fontsize=12)
            ax.set_ylabel('é¢‘æ•°', fontsize=12)
            ax.set_title('Consistency åˆ†æ•°åˆ†å¸ƒ', fontsize=13, fontweight='bold')
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # Consistency ç®±çº¿å›¾
        if 'mos_align' in self.df.columns:
            ax = axes[1, 1]
            ax.boxplot([self.df['mos_align']], vert=True, labels=['Consistency'],
                      patch_artist=True, boxprops=dict(facecolor='orange'))
            ax.set_ylabel('åˆ†æ•°', fontsize=12)
            ax.set_title('Consistency åˆ†æ•°ç®±çº¿å›¾', fontsize=13, fontweight='bold')
            ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        else:
            plt.savefig(os.path.join(self.output_dir, 'score_distributions.png'),
                       dpi=300, bbox_inches='tight')
        
        plt.close()
        print("ğŸ’¾ åˆ†æ•°åˆ†å¸ƒå›¾å·²ä¿å­˜")
    
    def plot_score_correlation(self, save_path: Optional[str] = None):
        """ç»˜åˆ¶ Quality ä¸ Consistency ç›¸å…³æ€§å›¾"""
        if 'mos_quality' not in self.df.columns or 'mos_align' not in self.df.columns:
            print("âš ï¸  ç¼ºå°‘å¿…è¦çš„åˆ—ï¼Œæ— æ³•ç»˜åˆ¶ç›¸å…³æ€§å›¾")
            return
        
        fig, ax = plt.subplots(figsize=(8, 6))
        
        ax.scatter(self.df['mos_quality'], self.df['mos_align'],
                  alpha=0.5, s=30, edgecolors='k', linewidth=0.5)
        
        # è®¡ç®—ç›¸å…³ç³»æ•°
        corr = self.df['mos_quality'].corr(self.df['mos_align'])
        
        ax.set_xlabel('Quality åˆ†æ•°', fontsize=12)
        ax.set_ylabel('Consistency åˆ†æ•°', fontsize=12)
        ax.set_title(f'Quality vs Consistency ç›¸å…³æ€§\nç›¸å…³ç³»æ•°: {corr:.3f}',
                    fontsize=13, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
        else:
            plt.savefig(os.path.join(self.output_dir, 'score_correlation.png'),
                       dpi=300, bbox_inches='tight')
        
        plt.close()
        print("ğŸ’¾ ç›¸å…³æ€§å›¾å·²ä¿å­˜")
    
    def check_data_quality(self):
        """æ£€æŸ¥æ•°æ®è´¨é‡ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ç­‰ï¼‰"""
        print("\n" + "=" * 80)
        print("ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥")
        print("=" * 80 + "\n")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing = self.df.isnull().sum()
        if missing.sum() > 0:
            print("âš ï¸  å‘ç°ç¼ºå¤±å€¼:")
            for col, count in missing[missing > 0].items():
                print(f"  â€¢ {col}: {count} ({count/len(self.df)*100:.1f}%)")
        else:
            print("âœ… æ— ç¼ºå¤±å€¼")
        
        # æ£€æŸ¥é‡å¤è¡Œ
        duplicates = self.df.duplicated().sum()
        if duplicates > 0:
            print(f"\nâš ï¸  å‘ç° {duplicates} ä¸ªé‡å¤è¡Œ")
        else:
            print("\nâœ… æ— é‡å¤è¡Œ")
        
        # æ£€æŸ¥åˆ†æ•°èŒƒå›´
        print("\nğŸ“Š åˆ†æ•°èŒƒå›´æ£€æŸ¥:")
        if 'mos_quality' in self.df.columns:
            q_min, q_max = self.df['mos_quality'].min(), self.df['mos_quality'].max()
            if q_min < 1 or q_max > 5:
                print(f"  âš ï¸  Quality åˆ†æ•°è¶…å‡ºèŒƒå›´ [1, 5]: [{q_min:.2f}, {q_max:.2f}]")
            else:
                print(f"  âœ… Quality åˆ†æ•°åœ¨æ­£å¸¸èŒƒå›´: [{q_min:.2f}, {q_max:.2f}]")
        
        if 'mos_align' in self.df.columns:
            c_min, c_max = self.df['mos_align'].min(), self.df['mos_align'].max()
            if c_min < 1 or c_max > 5:
                print(f"  âš ï¸  Consistency åˆ†æ•°è¶…å‡ºèŒƒå›´ [1, 5]: [{c_min:.2f}, {c_max:.2f}]")
            else:
                print(f"  âœ… Consistency åˆ†æ•°åœ¨æ­£å¸¸èŒƒå›´: [{c_min:.2f}, {c_max:.2f}]")
        
        # æ£€æŸ¥å›¾åƒæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        print("\nğŸ–¼ï¸  å›¾åƒæ–‡ä»¶æ£€æŸ¥:")
        missing_images = []
        for img_name in tqdm(self.df['name'], desc="æ£€æŸ¥å›¾åƒæ–‡ä»¶"):
            img_path = os.path.join(self.image_dir, img_name)
            if not os.path.exists(img_path):
                missing_images.append(img_name)
        
        if missing_images:
            print(f"  âš ï¸  å‘ç° {len(missing_images)} ä¸ªç¼ºå¤±çš„å›¾åƒæ–‡ä»¶")
            print(f"  å‰ 5 ä¸ª: {missing_images[:5]}")
        else:
            print(f"  âœ… æ‰€æœ‰å›¾åƒæ–‡ä»¶éƒ½å­˜åœ¨")
        
        print("=" * 80 + "\n")
    
    def analyze_image_properties(self, sample_size: int = 100):
        """åˆ†æå›¾åƒå±æ€§ï¼ˆå°ºå¯¸ã€æ ¼å¼ç­‰ï¼‰"""
        print("\n" + "=" * 80)
        print(f"ğŸ–¼ï¸  å›¾åƒå±æ€§åˆ†æ (é‡‡æ · {sample_size} å¼ )")
        print("=" * 80 + "\n")
        
        # éšæœºé‡‡æ ·
        sample_df = self.df.sample(min(sample_size, len(self.df)))
        
        widths, heights, sizes = [], [], []
        formats = {}
        
        for img_name in tqdm(sample_df['name'], desc="åˆ†æå›¾åƒ"):
            img_path = os.path.join(self.image_dir, img_name)
            try:
                img = Image.open(img_path)
                widths.append(img.width)
                heights.append(img.height)
                sizes.append(os.path.getsize(img_path) / 1024)  # KB
                
                fmt = img.format
                formats[fmt] = formats.get(fmt, 0) + 1
            except Exception as e:
                print(f"âš ï¸  æ— æ³•è¯»å– {img_name}: {e}")
        
        print(f"ğŸ“ å›¾åƒå°ºå¯¸:")
        print(f"  â€¢ å®½åº¦: å‡å€¼={np.mean(widths):.0f}, èŒƒå›´=[{min(widths)}, {max(widths)}]")
        print(f"  â€¢ é«˜åº¦: å‡å€¼={np.mean(heights):.0f}, èŒƒå›´=[{min(heights)}, {max(heights)}]")
        
        print(f"\nğŸ’¾ æ–‡ä»¶å¤§å°:")
        print(f"  â€¢ å‡å€¼: {np.mean(sizes):.1f} KB")
        print(f"  â€¢ èŒƒå›´: [{min(sizes):.1f}, {max(sizes):.1f}] KB")
        
        print(f"\nğŸ¨ å›¾åƒæ ¼å¼:")
        for fmt, count in formats.items():
            print(f"  â€¢ {fmt}: {count} ({count/len(widths)*100:.1f}%)")
        
        print("=" * 80 + "\n")
    
    def run_full_analysis(self):
        """è¿è¡Œå®Œæ•´çš„æ•°æ®åˆ†æ"""
        print("\n" + "=" * 80)
        print("ğŸš€ å¼€å§‹å®Œæ•´æ•°æ®åˆ†æ")
        print("=" * 80)
        
        # 1. åŸºæœ¬ç»Ÿè®¡
        self.print_basic_stats()
        
        # 2. æ•°æ®è´¨é‡æ£€æŸ¥
        self.check_data_quality()
        
        # 3. å›¾åƒå±æ€§åˆ†æ
        self.analyze_image_properties()
        
        # 4. å¯è§†åŒ–
        print("ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        self.plot_score_distributions()
        self.plot_score_correlation()
        
        print("\nâœ… æ•°æ®åˆ†æå®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°:", self.output_dir)


class DataPreprocessor:
    """æ•°æ®é¢„å¤„ç†å™¨"""
    
    def __init__(self, csv_path: str):
        """
        åˆå§‹åŒ–é¢„å¤„ç†å™¨
        
        Args:
            csv_path: CSV æ–‡ä»¶è·¯å¾„
        """
        self.df = pd.read_csv(csv_path)
        print(f"ğŸ“‚ åŠ è½½æ•°æ®: {csv_path}")
        print(f"ğŸ“Š æ ·æœ¬æ•°: {len(self.df)}")
    
    def remove_outliers(self, column: str, n_std: float = 3.0) -> pd.DataFrame:
        """
        ç§»é™¤å¼‚å¸¸å€¼ï¼ˆåŸºäºæ ‡å‡†å·®ï¼‰
        
        Args:
            column: åˆ—å
            n_std: æ ‡å‡†å·®å€æ•°
            
        Returns:
            å¤„ç†åçš„ DataFrame
        """
        mean = self.df[column].mean()
        std = self.df[column].std()
        
        lower_bound = mean - n_std * std
        upper_bound = mean + n_std * std
        
        outliers = (self.df[column] < lower_bound) | (self.df[column] > upper_bound)
        n_outliers = outliers.sum()
        
        print(f"ğŸ” {column} åˆ—:")
        print(f"  â€¢ æ£€æµ‹åˆ° {n_outliers} ä¸ªå¼‚å¸¸å€¼ (Â±{n_std}Ïƒ)")
        print(f"  â€¢ èŒƒå›´: [{lower_bound:.3f}, {upper_bound:.3f}]")
        
        self.df = self.df[~outliers]
        return self.df
    
    def normalize_scores(self, columns: list, target_range: Tuple[float, float] = (0, 1)):
        """
        å½’ä¸€åŒ–åˆ†æ•°åˆ°ç›®æ ‡èŒƒå›´
        
        Args:
            columns: è¦å½’ä¸€åŒ–çš„åˆ—ååˆ—è¡¨
            target_range: ç›®æ ‡èŒƒå›´ (min, max)
        """
        for col in columns:
            if col not in self.df.columns:
                continue
            
            min_val, max_val = self.df[col].min(), self.df[col].max()
            target_min, target_max = target_range
            
            self.df[col] = (self.df[col] - min_val) / (max_val - min_val) * \
                          (target_max - target_min) + target_min
            
            print(f"âœ… {col} å·²å½’ä¸€åŒ–åˆ° [{target_min}, {target_max}]")
    
    def balance_dataset(self, column: str, n_bins: int = 5) -> pd.DataFrame:
        """
        å¹³è¡¡æ•°æ®é›†ï¼ˆä½¿å„åˆ†æ•°åŒºé—´æ ·æœ¬æ•°ç›¸è¿‘ï¼‰
        
        Args:
            column: ç”¨äºåˆ†ç®±çš„åˆ—å
            n_bins: åˆ†ç®±æ•°
            
        Returns:
            å¹³è¡¡åçš„ DataFrame
        """
        # åˆ†ç®±
        self.df['bin'] = pd.cut(self.df[column], bins=n_bins, labels=False)
        
        # è®¡ç®—æ¯ä¸ªç®±çš„æ ·æœ¬æ•°
        bin_counts = self.df['bin'].value_counts().sort_index()
        min_count = bin_counts.min()
        
        print(f"\nğŸ“Š åˆ†ç®±ç»Ÿè®¡ ({column}):")
        for i, count in enumerate(bin_counts):
            print(f"  Bin {i}: {count} æ ·æœ¬")
        
        # ä¸‹é‡‡æ ·åˆ°æœ€å°æ•°é‡
        balanced_df = []
        for i in range(n_bins):
            bin_data = self.df[self.df['bin'] == i]
            sampled = bin_data.sample(min(len(bin_data), min_count), random_state=42)
            balanced_df.append(sampled)
        
        self.df = pd.concat(balanced_df, ignore_index=True)
        self.df = self.df.drop('bin', axis=1)
        
        print(f"\nâœ… æ•°æ®é›†å·²å¹³è¡¡ï¼Œæ€»æ ·æœ¬æ•°: {len(self.df)}")
        return self.df
    
    def save(self, output_path: str):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        self.df.to_csv(output_path, index=False)
        print(f"ğŸ’¾ å¤„ç†åçš„æ•°æ®å·²ä¿å­˜: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="æ•°æ®é›†åˆ†æå’Œé¢„å¤„ç†å·¥å…·",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest='command', help='å‘½ä»¤')
    
    # åˆ†æå‘½ä»¤
    analyze_parser = subparsers.add_parser('analyze', help='æ•°æ®é›†åˆ†æ')
    analyze_parser.add_argument('--csv', type=str, required=True, help='CSV æ–‡ä»¶è·¯å¾„')
    analyze_parser.add_argument('--image_dir', type=str, required=True, help='å›¾åƒç›®å½•')
    analyze_parser.add_argument('--output_dir', type=str, default='data_analysis',
                               help='è¾“å‡ºç›®å½•')
    
    # é¢„å¤„ç†å‘½ä»¤
    preprocess_parser = subparsers.add_parser('preprocess', help='æ•°æ®é¢„å¤„ç†')
    preprocess_parser.add_argument('--csv', type=str, required=True, help='CSV æ–‡ä»¶è·¯å¾„')
    preprocess_parser.add_argument('--output', type=str, required=True, help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    preprocess_parser.add_argument('--remove_outliers', action='store_true',
                                   help='ç§»é™¤å¼‚å¸¸å€¼')
    preprocess_parser.add_argument('--balance', action='store_true',
                                   help='å¹³è¡¡æ•°æ®é›†')
    
    args = parser.parse_args()
    
    if args.command == 'analyze':
        # æ•°æ®åˆ†æ
        analyzer = DatasetAnalyzer(args.csv, args.image_dir, args.output_dir)
        analyzer.run_full_analysis()
    
    elif args.command == 'preprocess':
        # æ•°æ®é¢„å¤„ç†
        preprocessor = DataPreprocessor(args.csv)
        
        if args.remove_outliers:
            print("\nğŸ”§ ç§»é™¤å¼‚å¸¸å€¼...")
            if 'mos_quality' in preprocessor.df.columns:
                preprocessor.remove_outliers('mos_quality')
            if 'mos_align' in preprocessor.df.columns:
                preprocessor.remove_outliers('mos_align')
        
        if args.balance:
            print("\nâš–ï¸  å¹³è¡¡æ•°æ®é›†...")
            if 'mos_quality' in preprocessor.df.columns:
                preprocessor.balance_dataset('mos_quality')
        
        preprocessor.save(args.output)
        print("\nâœ… é¢„å¤„ç†å®Œæˆï¼")
    
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
