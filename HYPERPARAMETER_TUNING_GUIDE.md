# è¶…å‚æ•°è°ƒä¼˜å®Œå…¨æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [ç°æœ‰å¯è°ƒå‚æ•°](#ç°æœ‰å¯è°ƒå‚æ•°)
2. [å…³é”®å‚æ•°è°ƒä¼˜å»ºè®®](#å…³é”®å‚æ•°è°ƒä¼˜å»ºè®®)
3. [å»ºè®®æ–°å¢å‚æ•°](#å»ºè®®æ–°å¢å‚æ•°)
4. [è‡ªåŠ¨åŒ–è¶…å‚æ•°æœç´¢](#è‡ªåŠ¨åŒ–è¶…å‚æ•°æœç´¢)
5. [å…¸å‹é…ç½®æ–¹æ¡ˆ](#å…¸å‹é…ç½®æ–¹æ¡ˆ)

---

## ğŸ›ï¸ ç°æœ‰å¯è°ƒå‚æ•°

### 1. åŸºç¡€è®­ç»ƒå‚æ•°

| å‚æ•° | å‘½ä»¤è¡Œ | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|--------|--------|----------|------|
| **epochs** | `--epochs` | 20 | 10-50 | è®­ç»ƒè½®æ•°ï¼Œæ•°æ®å°‘æ—¶å¯å¢åŠ  |
| **batch_size** | `--batch_size` | 32 | 8-128 | æ‰¹æ¬¡å¤§å°ï¼Œå—æ˜¾å­˜é™åˆ¶ |
| **lr** | `--lr` | 3e-5 | 1e-6 ~ 1e-3 | å­¦ä¹ ç‡ï¼Œå†»ç»“æ—¶å¯æ›´å¤§ |
| **weight_decay** | âŒ æœªæš´éœ² | 1e-4 | 1e-5 ~ 1e-3 | L2 æ­£åˆ™åŒ–ï¼Œé˜²è¿‡æ‹Ÿåˆ |

```bash
# ç¤ºä¾‹
python baseline.py --epochs 30 --batch_size 64 --lr 5e-5
```

---

### 2. æŸå¤±æƒé‡å‚æ•° â­ é‡è¦

| å‚æ•° | å‘½ä»¤è¡Œ | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|--------|--------|----------|------|
| **w_q** | `--w_q` | 0.5 | 0.3-0.7 | Quality æŸå¤±æƒé‡ |
| **w_c** | `--w_c` | 0.5 | 0.3-0.7 | Consistency æŸå¤±æƒé‡ |
| **w_exp** | `--w_exp` | 0.1 | 0.05-0.3 | Explanation æŸå¤±æƒé‡ |

**è°ƒä¼˜å»ºè®®**ï¼š
- å¦‚æœæ›´å…³æ³¨ **å›¾åƒè´¨é‡**ï¼š`--w_q 0.7 --w_c 0.3`
- å¦‚æœæ›´å…³æ³¨ **æ–‡å›¾å¯¹é½**ï¼š`--w_q 0.3 --w_c 0.7`
- **å¹³è¡¡æ¨¡å¼**ï¼ˆæ¨èï¼‰ï¼š`--w_q 0.5 --w_c 0.5`

```bash
# ç¤ºä¾‹ï¼šåé‡ consistency
python baseline.py --w_q 0.3 --w_c 0.7
```

---

### 3. æ®‹å·®å­¦ä¹ å‚æ•° ğŸ”¥ æ ¸å¿ƒ

| å‚æ•° | å‘½ä»¤è¡Œ | é»˜è®¤å€¼ | æ¨èèŒƒå›´ | è¯´æ˜ |
|------|--------|--------|----------|------|
| **use_residual_learning** | `--no_residual_learning` | True | - | ç¦ç”¨æ®‹å·®å­¦ä¹  |
| **residual_scale_q** | `--residual_scale_q` | 0.2 | 0.1-0.5 | Quality æ®‹å·®ç¼©æ”¾ |
| **residual_scale_c** | `--residual_scale_c` | 0.2 | 0.1-0.5 | Consistency æ®‹å·®ç¼©æ”¾ |

**è°ƒä¼˜ç­–ç•¥**ï¼š

| æ•°æ®è§„æ¨¡ | residual_scale_q | residual_scale_c | åŸå›  |
|----------|-----------------|-----------------|------|
| **<500 æ ·æœ¬** | 0.1 | 0.1 | æ•°æ®å°‘ï¼Œå¼ºçº¦æŸé˜²è¿‡æ‹Ÿåˆ |
| **500-3K** | 0.2 | 0.2 | âœ… é»˜è®¤å€¼ï¼Œå¹³è¡¡ |
| **3K-10K** | 0.3 | 0.3 | æ•°æ®å……è¶³ï¼Œå…è®¸æ›´å¤§è°ƒæ•´ |
| **>10K** | 0.4-0.5 | 0.4-0.5 | å¤§æ•°æ®ï¼Œå¯æ¿€è¿› |

```bash
# å°æ•°æ®é›†ï¼ˆä¿å®ˆï¼‰
python baseline.py --residual_scale_q 0.1 --residual_scale_c 0.1

# å¤§æ•°æ®é›†ï¼ˆæ¿€è¿›ï¼‰
python baseline.py --residual_scale_q 0.4 --residual_scale_c 0.4
```

---

### 4. CLIP å†»ç»“ç­–ç•¥ â„ï¸ é‡è¦

| å‚æ•° | å‘½ä»¤è¡Œ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|--------|------|
| **freeze_clip** | `--freeze_clip` | False | å®Œå…¨å†»ç»“ CLIP |
| **partial_freeze** | `--partial_freeze` | False | éƒ¨åˆ†å†»ç»“ï¼ˆæ¨èï¼‰|
| **freeze_layers** | `--freeze_layers` | 8 | å†»ç»“å‰ N å±‚ |

**ä¸åŒæ¨¡å‹çš„å±‚æ•°é…ç½®**ï¼š

| CLIP æ¨¡å‹ | æ€»å±‚æ•° | æ¨è freeze_layers | å¯è®­ç»ƒå±‚ |
|-----------|--------|-------------------|----------|
| **ViT-B/32** | 12 | 8-10 | 2-4 å±‚ |
| **ViT-B/16** | 12 | 8-10 | 2-4 å±‚ |
| **ViT-L/14** | 24 | 18-20 | 4-6 å±‚ |
| **ViT-L/14@336** | 24 | 20-22 | 2-4 å±‚ |

**å†»ç»“ç­–ç•¥å¯¹æ¯”**ï¼š

```bash
# ç­–ç•¥ 1: å®Œå…¨å¾®è°ƒï¼ˆæ•°æ®å……è¶³ï¼Œ>5Kï¼‰
python baseline.py
# å­¦ä¹ ç‡: 1e-5 ~ 3e-5

# ç­–ç•¥ 2: éƒ¨åˆ†å†»ç»“ï¼ˆæ¨èï¼Œæ•°æ®ä¸­ç­‰ 1K-5Kï¼‰â­
python baseline.py --partial_freeze --freeze_layers 18
# å­¦ä¹ ç‡: 3e-5 ~ 1e-4

# ç­–ç•¥ 3: å®Œå…¨å†»ç»“ï¼ˆæ•°æ®æå°‘ï¼Œ<500ï¼‰
python baseline.py --freeze_clip
# å­¦ä¹ ç‡: 1e-3 ~ 5e-3ï¼ˆå¯ä»¥ç”¨å¤§å­¦ä¹ ç‡ï¼‰
```

---

### 5. Refinement Module å‚æ•°ï¼ˆæ—§æ–¹æ¡ˆï¼Œä¸æ¨èä¸æ®‹å·®å­¦ä¹ åŒç”¨ï¼‰

| å‚æ•° | å‘½ä»¤è¡Œ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|--------|------|
| **use_refinement** | `--use_refinement` | False | å¯ç”¨ç²¾ç»†åŒ–æ¨¡å— |
| **refinement_layers** | `--refinement_layers` | 4 | Transformer å±‚æ•° |
| **refinement_heads** | `--refinement_heads` | 8 | æ³¨æ„åŠ›å¤´æ•° |
| **refinement_dim** | `--refinement_dim` | 256 | éšè—å±‚ç»´åº¦ |

**æ³¨æ„**ï¼šä¸æ®‹å·®å­¦ä¹ äº’æ–¥ï¼Œå»ºè®®ä½¿ç”¨æ®‹å·®å­¦ä¹ ã€‚

---

### 6. æ•°æ®å¢å¼ºå‚æ•°

| å‚æ•° | ä»£ç ä½ç½® | é»˜è®¤å€¼ | å¯è°ƒèŒƒå›´ |
|------|----------|--------|----------|
| **image_size** | `TrainingConfig` | 224 | 224-336 |
| **RandomResizedCrop scale** | ä»£ç ä¸­ | (0.8, 1.0) | (0.6, 1.0) |
| **test_size** | âŒ æœªæš´éœ² | 0.2 | 0.1-0.3 |

---

## ğŸ¯ å…³é”®å‚æ•°è°ƒä¼˜å»ºè®®

### åœºæ™¯ 1: æ•°æ®é‡ < 1Kï¼ˆå°æ•°æ®é›†ï¼‰

```bash
python baseline.py \
    --freeze_clip \
    --residual_scale_q 0.1 \
    --residual_scale_c 0.1 \
    --epochs 30 \
    --batch_size 16 \
    --lr 1e-3 \
    --w_q 0.5 \
    --w_c 0.5
```

**ç­–ç•¥**ï¼š
- â„ï¸ å®Œå…¨å†»ç»“ CLIPï¼ˆä¿æŠ¤é¢„è®­ç»ƒçŸ¥è¯†ï¼‰
- ğŸ“ å°æ®‹å·®ç¼©æ”¾ï¼ˆå¼ºçº¦æŸï¼‰
- ğŸ“š æ›´å¤š epochsï¼ˆå°æ•°æ®éœ€è¦å¤šè½®ï¼‰
- ğŸš€ å¤§å­¦ä¹ ç‡ï¼ˆåªè®­ç»ƒé¢„æµ‹å¤´ï¼‰

---

### åœºæ™¯ 2: æ•°æ®é‡ 1K-5Kï¼ˆä¸­ç­‰æ•°æ®é›†ï¼‰â­ æ¨è

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --residual_scale_q 0.2 \
    --residual_scale_c 0.2 \
    --epochs 20 \
    --batch_size 32 \
    --lr 3e-5 \
    --w_q 0.5 \
    --w_c 0.5
```

**ç­–ç•¥**ï¼š
- ğŸ§Š éƒ¨åˆ†å†»ç»“ï¼ˆå¹³è¡¡æ€§èƒ½å’Œæ³›åŒ–ï¼‰
- ğŸ“ ä¸­ç­‰æ®‹å·®ç¼©æ”¾ï¼ˆé»˜è®¤å€¼ï¼‰
- âš–ï¸ å¹³è¡¡çš„æŸå¤±æƒé‡

---

### åœºæ™¯ 3: æ•°æ®é‡ > 5Kï¼ˆå¤§æ•°æ®é›†ï¼‰

```bash
python baseline.py \
    --residual_scale_q 0.3 \
    --residual_scale_c 0.3 \
    --epochs 15 \
    --batch_size 64 \
    --lr 3e-5 \
    --w_q 0.5 \
    --w_c 0.5
```

**ç­–ç•¥**ï¼š
- ğŸ”¥ å®Œå…¨å¾®è°ƒï¼ˆæ•°æ®å……è¶³ï¼‰
- ğŸ“ è¾ƒå¤§æ®‹å·®ç¼©æ”¾ï¼ˆå…è®¸æ›´å¤§è°ƒæ•´ï¼‰
- ğŸ“¦ å¤§ batch sizeï¼ˆåŠ é€Ÿè®­ç»ƒï¼‰

---

## ğŸ’¡ å»ºè®®æ–°å¢å‚æ•°

### 1. Warmup æ¯”ä¾‹ï¼ˆå½“å‰ç¡¬ç¼–ç ï¼‰

**å½“å‰ä»£ç **ï¼š
```python
warmup_steps = int(0.05 * len(train_dl) * cfg.epochs)  # å›ºå®š 5%
```

**å»ºè®®ä¿®æ”¹**ï¼š
```python
# åœ¨ TrainingConfig æ·»åŠ 
self.warmup_ratio = 0.05  # å¯è°ƒæ•´ä¸º 0.01-0.1

# åœ¨ parser æ·»åŠ 
parser.add_argument('--warmup_ratio', type=float, help='Warmup steps ratio')

# åœ¨ main ä¸­ä½¿ç”¨
warmup_steps = int(cfg.warmup_ratio * len(train_dl) * cfg.epochs)
```

**è°ƒä¼˜å»ºè®®**ï¼š
- å°æ•°æ®é›†ï¼š`0.1`ï¼ˆæ›´é•¿ warmupï¼‰
- å¤§æ•°æ®é›†ï¼š`0.05`ï¼ˆé»˜è®¤ï¼‰
- å®Œå…¨å†»ç»“ï¼š`0.01`ï¼ˆå‡ ä¹ä¸éœ€è¦ warmupï¼‰

---

### 2. Dropout æ¯”ä¾‹

**å½“å‰ä»£ç **ï¼š
```python
nn.Dropout(0.1)  # å›ºå®šå€¼
```

**å»ºè®®æ·»åŠ **ï¼š
```python
self.dropout = 0.1  # å¯è°ƒæ•´ä¸º 0.0-0.3
```

**è°ƒä¼˜å»ºè®®**ï¼š
- æ— è¿‡æ‹Ÿåˆï¼š`0.0`ï¼ˆç§»é™¤ dropoutï¼‰
- è½»å¾®è¿‡æ‹Ÿåˆï¼š`0.1`ï¼ˆé»˜è®¤ï¼‰
- ä¸¥é‡è¿‡æ‹Ÿåˆï¼š`0.2-0.3`

---

### 3. å­¦ä¹ ç‡è°ƒåº¦å™¨ç±»å‹

**å½“å‰**ï¼šå›ºå®šä½¿ç”¨ `cosine_schedule_with_warmup`

**å»ºè®®æ–°å¢é€‰é¡¹**ï¼š
```bash
--scheduler cosine  # ä½™å¼¦é€€ç«ï¼ˆé»˜è®¤ï¼‰
--scheduler linear  # çº¿æ€§è¡°å‡
--scheduler step    # é˜¶æ¢¯è¡°å‡
--scheduler constant  # æ’å®šå­¦ä¹ ç‡
```

---

### 4. MLP éšè—å±‚ç»´åº¦

**å½“å‰ä»£ç **ï¼š
```python
self.q_delta_head = nn.Sequential(
    nn.Linear(dim, 128),  # å›ºå®š 128
    ...
)
```

**å»ºè®®æ·»åŠ **ï¼š
```python
self.hidden_dim_q = 128  # å¯è°ƒæ•´ä¸º 64-512
self.hidden_dim_c = 256  # Consistency çš„éšè—å±‚
```

---

### 5. æ¢¯åº¦è£å‰ª

**å½“å‰**ï¼šæœªä½¿ç”¨æ¢¯åº¦è£å‰ª

**å»ºè®®æ·»åŠ **ï¼š
```python
# åœ¨ TrainingConfig
self.max_grad_norm = 1.0  # 0 è¡¨ç¤ºä¸è£å‰ª

# åœ¨è®­ç»ƒå¾ªç¯
if cfg.max_grad_norm > 0:
    torch.nn.utils.clip_grad_norm_(model.parameters(), cfg.max_grad_norm)
```

**å»ºè®®å€¼**ï¼š
- è®­ç»ƒç¨³å®šï¼š`0`ï¼ˆä¸è£å‰ªï¼‰
- æ¢¯åº¦çˆ†ç‚¸ï¼š`1.0`ï¼ˆé»˜è®¤ï¼‰
- ä¸¥é‡çˆ†ç‚¸ï¼š`0.5`

---

### 6. æ—©åœ (Early Stopping)

**å»ºè®®æ·»åŠ **ï¼š
```python
self.early_stopping_patience = 5  # éªŒè¯é›†ä¸æå‡åˆ™åœæ­¢
self.early_stopping_min_delta = 0.001  # æœ€å°æå‡é˜ˆå€¼
```

---

### 7. æ ‡ç­¾å¹³æ»‘ (Label Smoothing)

å¯¹äºå›å½’ä»»åŠ¡å¯ä»¥ä½¿ç”¨è½¯æ ‡ç­¾ï¼š
```python
self.label_smoothing = 0.0  # 0.0-0.1
```

---

## ğŸ¤– è‡ªåŠ¨åŒ–è¶…å‚æ•°æœç´¢

### ä½¿ç”¨ Optuna è¿›è¡Œè‡ªåŠ¨è°ƒä¼˜

åˆ›å»º `hyperparam_search_advanced.py`ï¼š

```python
import optuna

def objective(trial):
    # æœç´¢ç©ºé—´
    lr = trial.suggest_loguniform('lr', 1e-6, 1e-3)
    residual_scale_q = trial.suggest_uniform('residual_scale_q', 0.1, 0.5)
    residual_scale_c = trial.suggest_uniform('residual_scale_c', 0.1, 0.5)
    freeze_layers = trial.suggest_int('freeze_layers', 16, 22, step=2)
    w_q = trial.suggest_uniform('w_q', 0.3, 0.7)
    w_c = 1.0 - w_q
    
    # è®­ç»ƒå¹¶è¿”å›éªŒè¯é›† SROCC
    srocc = train_with_params(lr, residual_scale_q, residual_scale_c, 
                              freeze_layers, w_q, w_c)
    return srocc

# è¿è¡Œä¼˜åŒ–
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

print(f"Best params: {study.best_params}")
print(f"Best SROCC: {study.best_value}")
```

**æ¨èæœç´¢çš„å‚æ•°**ï¼š
1. â­ `lr` (æœ€é‡è¦)
2. â­ `residual_scale_q/c`
3. â­ `freeze_layers`
4. `w_q` / `w_c`
5. `batch_size`

---

## ğŸ“Š å…¸å‹é…ç½®æ–¹æ¡ˆå¯¹æ¯”

### æ–¹æ¡ˆ A: å¿«é€ŸéªŒè¯ï¼ˆ5 åˆ†é’Ÿï¼‰

```bash
python baseline.py \
    --freeze_clip \
    --epochs 10 \
    --batch_size 64 \
    --lr 1e-3
```

---

### æ–¹æ¡ˆ B: å¹³è¡¡æ€§èƒ½ï¼ˆ20 åˆ†é’Ÿï¼‰â­ æ¨è

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --residual_scale_q 0.2 \
    --residual_scale_c 0.2 \
    --epochs 20 \
    --batch_size 32 \
    --lr 3e-5 \
    --w_q 0.5 \
    --w_c 0.5
```

---

### æ–¹æ¡ˆ C: æè‡´æ€§èƒ½ï¼ˆ1 å°æ—¶+ï¼‰

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 20 \
    --residual_scale_q 0.25 \
    --residual_scale_c 0.25 \
    --epochs 50 \
    --batch_size 16 \
    --lr 2e-5 \
    --w_q 0.4 \
    --w_c 0.6
```

---

### æ–¹æ¡ˆ D: é‡è§† Quality

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --w_q 0.7 \
    --w_c 0.3 \
    --residual_scale_q 0.3 \
    --residual_scale_c 0.15
```

---

### æ–¹æ¡ˆ E: é‡è§† Consistency

```bash
python baseline.py \
    --partial_freeze \
    --freeze_layers 18 \
    --w_q 0.3 \
    --w_c 0.7 \
    --residual_scale_q 0.15 \
    --residual_scale_c 0.3
```

---

## ğŸ” å‚æ•°æ•æ„Ÿåº¦åˆ†æ

æ ¹æ®ç»éªŒï¼Œå„å‚æ•°å¯¹æ€§èƒ½çš„å½±å“ç¨‹åº¦ï¼š

| å‚æ•° | æ•æ„Ÿåº¦ | å½±å“ SROCC | å»ºè®®ä¼˜å…ˆçº§ |
|------|--------|------------|-----------|
| **lr** | ğŸ”¥ğŸ”¥ğŸ”¥ å¾ˆé«˜ | Â±0.05 | â­â­â­ æœ€ä¼˜å…ˆ |
| **freeze_layers** | ğŸ”¥ğŸ”¥ é«˜ | Â±0.03 | â­â­â­ æœ€ä¼˜å…ˆ |
| **residual_scale_c** | ğŸ”¥ğŸ”¥ é«˜ | Â±0.02 | â­â­ ä¼˜å…ˆ |
| **w_q / w_c** | ğŸ”¥ ä¸­ | Â±0.01 | â­â­ ä¼˜å…ˆ |
| **residual_scale_q** | ğŸ”¥ ä¸­ | Â±0.01 | â­ æ¬¡è¦ |
| **batch_size** | ğŸŒ¡ï¸ ä½ | Â±0.005 | â­ æ¬¡è¦ |
| **epochs** | ğŸŒ¡ï¸ ä½ | - | - å¤Ÿç”¨å³å¯ |

---

## ğŸ“ è°ƒå‚ç»éªŒæ³•åˆ™

### 1. ä»ä¿å®ˆå¼€å§‹
```bash
# ç¬¬ä¸€æ¬¡è®­ç»ƒï¼šä½¿ç”¨é»˜è®¤ + éƒ¨åˆ†å†»ç»“
python baseline.py --partial_freeze --freeze_layers 18
```

### 2. è§‚å¯Ÿè®­ç»ƒæ›²çº¿
- **Train loss ä¸‹é™ï¼ŒVal loss ä¸Šå‡** â†’ è¿‡æ‹Ÿåˆ
  - å¢å¤§ `freeze_layers`ï¼ˆå¦‚ 18â†’20ï¼‰
  - å‡å° `residual_scale`ï¼ˆå¦‚ 0.2â†’0.15ï¼‰
  - å¢å¤§ `weight_decay`
  
- **Train & Val loss éƒ½å¾ˆé«˜** â†’ æ¬ æ‹Ÿåˆ
  - å‡å° `freeze_layers`ï¼ˆå¦‚ 18â†’16ï¼‰
  - å¢å¤§ `residual_scale`ï¼ˆå¦‚ 0.2â†’0.3ï¼‰
  - å¢å¤§ `lr`

- **Train loss ä¸‹é™æ…¢** â†’ å­¦ä¹ ç‡é—®é¢˜
  - å°è¯•æ›´å¤§ `lr`ï¼ˆå¦‚ 3e-5 â†’ 5e-5ï¼‰

### 3. è¿­ä»£ä¼˜åŒ–
```
Baseline â†’ è°ƒ lr â†’ è°ƒ freeze_layers â†’ è°ƒ residual_scale â†’ è°ƒ loss_weight
```

---

## ğŸ“ å¿«é€Ÿæ£€æŸ¥æ¸…å•

è®­ç»ƒå‰æ£€æŸ¥ï¼š
- [ ] å­¦ä¹ ç‡æ˜¯å¦é€‚é…å†»ç»“ç­–ç•¥ï¼Ÿ
  - å®Œå…¨å†»ç»“: `1e-3`
  - éƒ¨åˆ†å†»ç»“: `3e-5 ~ 1e-4`
  - å®Œå…¨å¾®è°ƒ: `1e-5 ~ 3e-5`
  
- [ ] æ®‹å·®ç¼©æ”¾æ˜¯å¦é€‚é…æ•°æ®é‡ï¼Ÿ
  - <1K: `0.1`
  - 1K-5K: `0.2`
  - >5K: `0.3+`

- [ ] Batch size æ˜¯å¦å……åˆ†åˆ©ç”¨æ˜¾å­˜ï¼Ÿ
  - æ˜¾å­˜å……è¶³æ—¶å°½é‡ç”¨å¤§ batch (32-64)

- [ ] æŸå¤±æƒé‡æ˜¯å¦å¹³è¡¡ï¼Ÿ
  - é€šå¸¸ `w_q = w_c = 0.5` æœ€ç¨³å®š

---

## ğŸš€ é«˜çº§æŠ€å·§

### 1. ä¸¤é˜¶æ®µè®­ç»ƒ

```bash
# é˜¶æ®µ 1: å†»ç»“è®­ç»ƒï¼ˆå¿«é€Ÿæ”¶æ•›ï¼‰
python baseline.py --freeze_clip --epochs 10 --lr 1e-3

# é˜¶æ®µ 2: éƒ¨åˆ†è§£å†»å¾®è°ƒï¼ˆæå‡æ€§èƒ½ï¼‰
python baseline.py --partial_freeze --freeze_layers 20 \
    --epochs 20 --lr 1e-5 \
    # åŠ è½½é˜¶æ®µ 1 çš„æƒé‡
```

### 2. æ¸è¿›å¼è§£å†»

```bash
# ä»å†»ç»“ 22 å±‚å¼€å§‹ï¼Œé€æ­¥è§£å†»
--freeze_layers 22  # Epoch 1-10
--freeze_layers 20  # Epoch 11-20
--freeze_layers 18  # Epoch 21-30
```

### 3. å¾ªç¯å­¦ä¹ ç‡ (Cyclic LR)

åœ¨æŸäº›æƒ…å†µä¸‹æ¯” cosine æ›´å¥½ï¼Œå¯ä»¥é€ƒç¦»å±€éƒ¨æœ€ä¼˜ã€‚

---

**æœ€åæ›´æ–°**: 2025-10-20  
**ç‰ˆæœ¬**: 2.0

